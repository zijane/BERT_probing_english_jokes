{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains code of lexical ans syntactic probing of BERT."
      ],
      "metadata": {
        "id": "ceDLsFCTbN2G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BaSxDaNY0x0"
      },
      "source": [
        "#### Experiment: Distribution of jokes and non-jokes with the same vocabulary in the BERT-family models' vector space.\n",
        "\n",
        "First of all, jokes and non-jokes were distributed in the vector space of the BERT family models ALBERT, DistilBERT, multilingual BERT, and Roberta-base. The initial dataset comprised 15,000 jokes and 15,000 non-jokes with similar vocabulary. They were vectorised using each of the above models, after which the dimension was reduced to 2 using the UMAP algorithm. Non-humorous texts are marked in green, humorous ones in red.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading and vectorizing data"
      ],
      "metadata": {
        "id": "ltgh0TxBGYMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O_Y-TI_Y1KN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "rom transformers import BertModel, BertPreTrainedModel, BertTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXRDllOmY1Ow"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiZwJi3nY1Sx"
      },
      "outputs": [],
      "source": [
        "\n",
        "!ls /content/gdrive/MyDrive/trained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0vEdFBBY1WO"
      },
      "outputs": [],
      "source": [
        "ffrom transformers import BertModel, BertPreTrainedModel, BertTokenizer, AutoTokenizer, AutoModel, DistilBertModel, RobertaTokenizer, RobertaModel, TFBertModel, TFBertTokenizer, AlbertModel\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
        "\n",
        "#bert_model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", torch_dtype=torch.float32)\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "#bert_model = RobertaModel.from_pretrained('roberta-base')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "#bert_model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "                \"bert-base-uncased\", do_lower_case=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjHoLuG7Y1aF"
      },
      "outputs": [],
      "source": [
        "dt_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/jokes_exp_triggers_24k.json\", lines= True)\n",
        "dt_reddit_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/reddit_jokes.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ15NWnNfp8t"
      },
      "outputs": [],
      "source": [
        "jokes = [str(i+ \" \" + u).lower() for i,u in zip(dt_reddit_jokes[\"title\"][:20000], dt_reddit_jokes[\"body\"][:20000]) if len(str(i+ \" \" + u)) <= 256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A4s9BEc6a6n"
      },
      "outputs": [],
      "source": [
        "jokes = jokes[:15000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il4Z1CWtCeEo"
      },
      "outputs": [],
      "source": [
        "j_vocab = [u.lower() for i in jokes for u in i.replace(\".\", \" \").replace(\"’s\", \" is \")\n",
        "                                              .replace(\"!\", \" \").replace(\"'s\", \" is \")\n",
        "                                              .replace(\",\", \" \").replace(\"–\", \"\")\n",
        "                                              .replace(\":\", \"\").replace(\"*\", \"\")\n",
        "                                              .replace(\"\\n\",\" \").replace(\"-\",\"\")\n",
        "                                              .replace(\"?\", \" \").split(\" \")]\n",
        "\n",
        "len(j_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFWaxjXB3rq"
      },
      "outputs": [],
      "source": [
        "dt_n_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/length_comp_news.json\", lines=True)\n",
        "dt_n_sec = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/unfiltered_news_v3.json\", lines=True)\n",
        "dt_n_thi = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Tweets.csv\")\n",
        "dt_n_fou = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Twitter_Data.csv\")\n",
        "dt_f_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/eng_literature.json\", lines=True)\n",
        "dt_n_five = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/News_Category_Dataset_v3.json\", lines=True)\n",
        "dt_n_six = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/bbc_news.csv\")\n",
        "dt_n_sev = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/abcnews-date-text.csv\")\n",
        "dt_n_eig = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/uci-news-aggregator.csv\")\n",
        "dt_n_nine = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/exp_trig_data_news_filtered.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOToH8yCCt_e"
      },
      "outputs": [],
      "source": [
        "news = [i for i in dt_n_one[\"headline\"] if len(i) <= 256] +  [i for i in dt_n_one[\"news_preproc\"] if len(i) <= 256] +  [i for i in dt_n_sec[\"headline\"] if len(i) <= 256] + [i for i in dt_n_sec[\"short_description\"] if len(i) <= 256] +  [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if i != None and len(i) <= 256] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if len(i) <= 256 and i != None] + [i for i in dt_n_thi[\"text\"].fillna(\"no\") if len(i) <= 256] + [i for i in dt_n_five[\"headline\"] if len(i) <= 256] + [i for i in dt_n_five[\"short_description\"] if len(i) <= 256]+ [i for i in dt_n_six[\"description\"] if len(i) <= 256] + [i for i in dt_n_six[\"title\"] if len(i) <= 256] + [i for i in dt_n_sev[\"headline_text\"] if len(i) <= 256] + [i for i in dt_n_eig[\"TITLE\"] if len(i) <= 256]  +  [i for i in dt_n_nine[\"headline\"] if  len(i) <= 256]\n",
        "len(news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoWBaXzgHBrQ"
      },
      "outputs": [],
      "source": [
        "#resultss = []\n",
        "for item in tqdm(news, total=len(news)):\n",
        "  new = item.lower().replace(\",\", \" \").replace(\".\", \" \").replace('\"', \" \").replace('“', \"\").replace(\"!\", \" \").replace(\"?\", \" \").replace(\":\", \" \").replace(\"\\n\", \" \").split(\" \")\n",
        "  comparison = list(set(j_vocab) & set(new))\n",
        "  if len(new) - len(comparison) == 0:\n",
        "    resultss.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEDykiwcHfJ7"
      },
      "outputs": [],
      "source": [
        "results = results[:15000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLnSDoS4HJCJ"
      },
      "outputs": [],
      "source": [
        "news = [i for i in results ]\n",
        "n_vocab = list(set([u.lower() for i in news for u in i.replace(\",\", \" \").replace(\".\", \" \").replace('\"', \" \").replace('“', \"\").replace(\"!\", \" \").replace(\"?\", \" \").replace(\":\", \" \").replace(\"\\n\", \" \").split(\" \")]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHyuj2behdkI"
      },
      "outputs": [],
      "source": [
        "def bert_embed(sent):\n",
        "  text = sent.lower().replace('\"', '') # убираем лишние кавычки и приводим к нижнему регистру\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\" # добавляем начальные метки, указываем границы анализируемого предложения\n",
        "\n",
        "  # делим предложения на токены\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  encodings = tokenizer(marked_text) # получаем начальные  представления\n",
        "\n",
        "  # Сопоставляем токены с их словарными индексами.\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  # Посмотреть на токены и индексы.\n",
        "  #for tup in zip(tokenized_text, indexed_tokens):\n",
        "  #    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "      # Оценка модели вернет различное количество объектов в зависимости от того, как она была настроена в предыдущем вызове `from_pre trained`.\n",
        "      # В этом случае, поскольку мы установили ' output_hidden_states = True, третьим элементом будут скрытые состояния из всех слоев.\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2] # берем скрытые состояния\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0) # предобрабатываем полученные скрытые состояния: объединяем последовательность тензоров вдоль новой новой размерности\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1) # Возвращает новый тензор, где удалена часть входных данных с размером 1.\n",
        "  token_embeddings = token_embeddings.permute(1,0,2) # перестановка данных для легкого изменения размеров тензора.\n",
        "\n",
        "  token_embeddings.size() # векторные представления имеют размерность 22  x 768\n",
        "  # Stores the token vectors, with shape [22 x 768]\n",
        "  token_vecs_sum = []\n",
        "\n",
        "  # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "  # For each token in the sentence...\n",
        "  for token in token_embeddings:\n",
        "\n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Sum the vectors from the last four layers. # берем векторные представления с последних 4 слоев и суммируем их.\n",
        "      sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "      # Use `sum_vec` to represent `token`.\n",
        "      token_vecs_sum.append(sum_vec)\n",
        "\n",
        "  vector = sum(token_vecs_sum) / len(token_vecs_sum)\n",
        "  return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXVdCSuRhdff"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "missed = []\n",
        "embedded = []\n",
        "for joke in tqdm(jokes, total=len(jokes)):\n",
        "  vector = bert_embed(sent = joke)\n",
        "  embedded.append({\"text\": joke, \"label\":0, \"vector\": vector})\n",
        "\n",
        "for new in tqdm(resultss, total=len(resultss)):\n",
        "  vector = bert_embed(sent = new)\n",
        "  embedded.append({\"text\": new, \"label\":1, \"vector\": vector})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L35wFB_M-VhB"
      },
      "outputs": [],
      "source": [
        "#### сохранение данных\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "a = torch.rand(3,4,5)\n",
        "\n",
        "# save\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_jokes_news_same_30000_finn.pickle', 'wb') as handle:\n",
        "    pickle.dump(embedded, handle)\n",
        "\n",
        "# open\n",
        "#with open('filename.pickle', 'rb') as handle:\n",
        "#    b = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Applying UMAP algorithm"
      ],
      "metadata": {
        "id": "cFSM-qN5FoT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rS9cTOQs4ev"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_jokes_news_same_30000_finn.pickle', 'rb') as handle:\n",
        "    words_embed = pickle.load(handle)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V26gGiV7tKc7"
      },
      "outputs": [],
      "source": [
        "jokes = [i for i in embedded if i[\"label\"] == 0 ]\n",
        "j_vocab = list(set([u for i in jokes for u in i['text'].replace(\",\", \" \").replace('\"', \" \").replace('“', \"\").replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\":\", \" \").replace(\"\\n\", \" \").split(\" \")]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbcojJfaufCw"
      },
      "outputs": [],
      "source": [
        "news = [i[\"text\"] for i in embedded if i[\"label\"] == 1 ]\n",
        "n_vocab = list(set([u.lower() for i in news for u in i.replace(\",\", \" \").replace(\".\", \" \").replace('\"', \" \").replace('“', \"\").replace(\"!\", \" \").replace(\"?\", \" \").replace(\":\", \" \").replace(\"\\n\", \" \").split(\" \")]))\n",
        "print(len(n_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA5TZH1lhxLC"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHyJGzduhdba"
      },
      "outputs": [],
      "source": [
        "#UMAP-LEARN\n",
        "import umap\n",
        "\n",
        "umap_text = umap.UMAP(n_components=2, random_state=100)\n",
        "umap_reduced = umap_text.fit_transform([i[\"vector\"].numpy() for i in embedded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHSBhwy5hdXL"
      },
      "outputs": [],
      "source": [
        "\n",
        "####Картинка UMAP\n",
        "fig, ax = plt.subplots(1,1, figsize= (13, 15))\n",
        "#ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(umap_reduced[:, 0], umap_reduced[:, 1], c=[\"red\" if i[\"label\"] == 0 else \"green\" for i in embedded], s=100, alpha=0.1) # train_b[:, 0], train_b[:, 1], c=list(k_means_bert) - нужно заменить, чтобы получить виз-цию результатов для Берта.\n",
        "\n",
        "\n",
        "#plt.xlim(xmin=0, xmax=30)\n",
        "# only show 100 - 1600 on y-axis.\n",
        "#plt.ylim(ymin=0, ymax=30)\n",
        "\n",
        "ax.set_xlabel('$X$')\n",
        "ax.set_ylabel('$Y$')\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.4,\n",
        "                    hspace=0.4)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3yoJfAQjAqB"
      },
      "source": [
        "#### Experiment: Assessing the impact of word polysemy on the perception of text as humorous\n",
        "\n",
        "At the first stage of the experiment, the context-specific vectorisation of words was analysed: was a particular word present in the joke or not. To establish that, selected jokes and news with the same vocabulary comprising both polysemic and non-polysemic words were taken. 8 polysemic nouns (school, life, right, home) and verbs (have, hear, take, tell, say) were selected for the analysis, along with 8 non-polysemic nouns (animal, murder, mom, police, divorce) and verbs (power, rain, rid, own, thank). Words’ polysemy was determined by the number of synsets in their description in WordNet. The part of speech was determined using a spaCy library English-language model. Humorous and non-humorous texts were selected according to the word’s part of speech. The selected jokes and non-jokes were vectorised using the “bert-base-uncased” model and processed by the UMAP algorithm.  Humorous texts are marked in red, non-humorous ones in green."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDw8Zem6XghA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBJp-asAXxhx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iybN7VRgaaml"
      },
      "outputs": [],
      "source": [
        "\n",
        "!ls /content/gdrive/MyDrive/trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrJfFdcgXbuB"
      },
      "outputs": [],
      "source": [
        "dt_n_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/length_comp_news.json\", lines=True)\n",
        "dt_n_sec = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/unfiltered_news_v3.json\", lines=True)\n",
        "dt_n_thi = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Tweets.csv\")\n",
        "dt_n_fou = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Twitter_Data.csv\")\n",
        "dt_f_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/eng_literature.json\", lines=True)\n",
        "dt_n_five = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/News_Category_Dataset_v3.json\", lines=True)\n",
        "dt_n_six = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/bbc_news.csv\")\n",
        "dt_n_sev = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/abcnews-date-text.csv\")\n",
        "dt_n_eig = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/uci-news-aggregator.csv\")\n",
        "dt_n_nine = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/exp_trig_data_news_filtered.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDIDangA4QwO"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "model = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "ms_razbor = []\n",
        "for i in  school_jokes:\n",
        "  for token in model(i):\n",
        "    if token.pos_ == \"NOUN\":\n",
        "      ms_razbor.append({\"text\":i, \"word\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_})\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBLRuIGwZLBW"
      },
      "outputs": [],
      "source": [
        "dt_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/jokes_exp_triggers_24k.json\", lines= True)\n",
        "dt_reddit_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/reddit_jokes.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-_r13kIcHHS"
      },
      "outputs": [],
      "source": [
        "dt_reddit_jokes[\"joke\"] = [str(i+ \" \" + u) for i,u in zip(dt_reddit_jokes[\"title\"], dt_reddit_jokes[\"body\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9uzCn2hAit8"
      },
      "outputs": [],
      "source": [
        "words = [\"school\", \"home\", \"right\", \"life\"] #time\n",
        "word = words[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXrAvm6narSC"
      },
      "outputs": [],
      "source": [
        "school_jokes = [i for i in dt_jokes[\"joke\"] if word in i and len(i) <= 256] + [i.lower() for i in dt_reddit_jokes[\"joke\"] if word in i and len(i) <= 256]\n",
        "school_jokes = school_jokes[:500]\n",
        "j_vocab = [u.lower() for i in school_jokes for u in i.replace(\".\", \" \").replace(\"’s\", \" is \")\n",
        "                                              .replace(\"!\", \" \").replace(\"'s\", \" is \")\n",
        "                                              .replace(\",\", \" \").replace(\"–\", \"\")\n",
        "                                              .replace(\":\", \"\").replace(\"*\", \"\")\n",
        "                                              .replace(\"\\n\",\" \").replace(\"-\",\"\")\n",
        "                                              .replace(\"?\", \" \").split(\" \")]\n",
        "\n",
        "len(school_jokes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd3jypM8fFBm"
      },
      "outputs": [],
      "source": [
        "school_news = [i for i in dt_n_one[\"headline\"] if word in i.lower() and len(i) <= 256] + [i for i in dt_n_one[\"news_preproc\"] if word in i.lower() and len(i) <= 256] + [i for i in dt_n_sec[\"headline\"] if word in i.lower() and len(i) <= 256] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower() and len(i) <= 256] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None and len(i) <= 256] + [i for i in dt_n_sec[\"headline\"] if word in i.lower() and len(i) <= 256] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower() and len(i) <= 256] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and  len(i) <= 256] + [i for i in dt_n_sec[\"headline\"] if word in i.lower() and len(i) <= 256] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower() and len(i) <= 256] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_thi[\"text\"].fillna(\"no\") if word in i.lower()] + [i for i in dt_n_five[\"headline\"] if word in i.lower()] + [i for i in dt_n_five[\"short_description\"] if word in i.lower()]+ [i for i in dt_n_six[\"description\"] if word in i.lower()] + [i for i in dt_n_six[\"title\"] if word in i.lower()] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [i for i in dt_n_sec[\"headline\"] if word in i.lower()] +  [i for i in dt_n_sec[\"short_description\"] if word in i.lower()] + [str(i) for i in dt_n_fou[\"clean_text\"].fillna(\"no\") if word in i and i != None] + [i for i in dt_n_thi[\"text\"].fillna(\"no\") if word in i.lower()] + [i for i in dt_n_five[\"headline\"] if word in i.lower()] + [i for i in dt_n_five[\"short_description\"] if word in i.lower()]+ [i for i in dt_n_six[\"description\"] if word in i.lower()] + [i for i in dt_n_sev[\"headline_text\"] if word in i.lower()] + [i for i in dt_n_eig[\"TITLE\"] if word in i.lower() and len(i) <= 256]  + [i for i in dt_n_nine[\"headline\"] if word in i.lower() and len(i) <= 256]\n",
        "len(school_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCkBFM07c-aN"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for item in tqdm(school_news, total=len(school_news)):\n",
        "  new = item.lower().split(\" \")\n",
        "  comparison = list(set(j_vocab) & set(new))\n",
        "  if len(new) - len(comparison) == 0:\n",
        "    results.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSyK-Bq8d-XM"
      },
      "outputs": [],
      "source": [
        "all_data = [{\"text\":i, \"text_preproc\": i.lower(), \"label\": 1} for i in results[:len(school_jokes)]] + [ {\"text\":i, \"text_preproc\": i.lower(), \"label\": 0 } for i in school_jokes]\n",
        "len(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyDADsFlYmVa"
      },
      "outputs": [],
      "source": [
        "def bert_embed(sent):\n",
        "  text = sent.lower().replace('\"', '')\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  encodings = tokenizer(marked_text)\n",
        "\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "\n",
        "      hidden_states = outputs[2]\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "  token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "  token_embeddings.size()\n",
        "  token_vecs_sum = []\n",
        "\n",
        "\n",
        "  for token in token_embeddings:\n",
        "\n",
        "\n",
        "      sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "      token_vecs_sum.append(sum_vec)\n",
        "\n",
        "  vector = sum(token_vecs_sum) / len(token_vecs_sum)\n",
        "  return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7nOiT4PzoNU"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "                \"bert-base-uncased\", do_lower_case=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikF1jCXu6vH-"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "missed = []\n",
        "embedded = []\n",
        "for diction in tqdm(all_data, total=len(all_data)):\n",
        "  if len(diction[\"text_preproc\"]) > 512:\n",
        "    missed.append(diction)\n",
        "  else:\n",
        "    vector = bert_embed(sent =diction[\"text_preproc\"])\n",
        "    diction[\"vector\"]= vector#\n",
        "    embedded.append(diction)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKfDVETi0VV4"
      },
      "outputs": [],
      "source": [
        "len(missed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRLoBG2F6vdY"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from sklearn.cluster import AffinityPropagation, MeanShift\n",
        "from scipy.spatial import distance\n",
        "\n",
        "all_res = []\n",
        "count_clusters = []\n",
        "\n",
        "clustering = MeanShift(bandwidth = 30).fit([item[\"vector\"].numpy() for item in embedded]) #######  проблема в снижении размерности???????\n",
        "centroids = clustering.cluster_centers_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzXRhW4wMzww"
      },
      "outputs": [],
      "source": [
        "all_res = []\n",
        "for item, cluster in zip(embedded, clustering.labels_ ):\n",
        "  item[\"cluster\"] =cluster\n",
        "  all_res.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G4DGX6vOO11"
      },
      "outputs": [],
      "source": [
        "m_res = pd.DataFrame(all_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo5xTSl86vqj"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVtYmtp66vuD"
      },
      "outputs": [],
      "source": [
        "#UMAP-LEARN\n",
        "import umap\n",
        "\n",
        "umap_text = umap.UMAP(n_components=2, random_state=100)\n",
        "umap_reduced = umap_text.fit_transform([item[\"vector\"].numpy() for item in embedded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So3Rk0WOP4bG"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1, figsize= (13, 15))\n",
        "#ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(umap_reduced[:,0], umap_reduced[:,1], c=[ \"red\" if i[\"label\"]==0 else \"green\" for i in embedded], alpha=0.5)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment with polysemic and non-polysemic word and its contexts\n",
        "We conducted an experiment to assess the effectiveness of clustering contextualised BERT vectors of polysemic and non-polysemic words. With the help of WordNet, 15 polysemic nouns with more than one synset, and 15 non-polysemic nouns with a single synset have been selected from 100 joke punchlines. 500 fragments were selected from news headlines and texts, and from fiction books in English, containing the same polysemic words. The contexts for each of the selected words were vectorised using a “bert-base-uncased” model. The resulting vector representations were clustered for each word individually using the MeanShift algorithm. For each word was also calculated the cosine distance between the centroids of its context of the use clusters, to identify the clusters most removed from each other.\n"
      ],
      "metadata": {
        "id": "rfEtIT6BbxFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Loading and preparation of non-jokes (news and fiction literature), and NOUNS from 100 jokes"
      ],
      "metadata": {
        "id": "EuBRemnkpS5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "OvFo5ZfWbvUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-FlC0GUb0U3"
      },
      "outputs": [],
      "source": [
        "#Загрузка библиотек\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfhq4_2ob685"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7S_mbclb94T"
      },
      "outputs": [],
      "source": [
        "stop_w = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx4PphnIfX6H"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx-iOICGfawP"
      },
      "outputs": [],
      "source": [
        "\n",
        "!ls /content/gdrive/MyDrive/trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgwurD-m9FWS"
      },
      "outputs": [],
      "source": [
        "stop_symbols = [',', \".\", \";\", \":\", \"!\", \"'\", '\"', \"/\", '\\\\', '-', '–' '(', \")\", '=', '+', \"—\", '’', '#', \"?\", \"...\", \" \"]\n",
        "test_df = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/exp_triggers_test_df_bigdata_38k.csv\")\n",
        "test_df[\"label_res\"] =  test_df[\"label\"].apply(lambda x: \"joke\" if x == 0 else \"non-joke\")\n",
        "test_df[\"text\"] =  [ i.replace('...', '.').replace(\"  \", ' ') for  i in test_df[\"text\"]]\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].fillna(test_df[\"text\"])\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].apply(lambda i: str(i + \" .\") if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] =  test_df[\"text\"].apply(lambda i: None if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] = test_df[\"text\"].fillna(test_df[\"text_unpreproc\"])\n",
        "test_df[\"text\"]  = [i.lower().replace('.', ' .').replace('!', ' !').replace('?', ' ?') for i in test_df[\"text\"]]\n",
        "#test_df[\"text\"].apply(lambda i: str(i + \".\") if i[-1] not in stop_symbols else i)\n",
        "y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=2)\n",
        "test_df= test_df.groupby([\"label\"]).head(100)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df = test_df[test_df[\"label\"] == 0].reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "uvuz8lVxVIw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBtPDQADe0By"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "model = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "ms_razbor = []\n",
        "for i in test_df[\"punchline\"]:\n",
        "  for token in model(i):\n",
        "    if token.pos_ == \"NOUN\":\n",
        "      count_m = len(wn.synsets(token.lemma_, pos=wn.NOUN))\n",
        "      if count_m ==1:\n",
        "        ms_razbor.append({\"punchline\":i, \"word\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_, \"count_word_net\": 1})\n",
        "      elif count_m > 1:\n",
        "        ms_razbor.append({\"punchline\":i, \"word\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_, \"count_word_net\": 2})\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_gyepbEwZ9e"
      },
      "outputs": [],
      "source": [
        "def preproc(text):\n",
        "  text = re.sub('<HTML>\\n\\n<HEAD>\\n\\n <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\\n\\n <META NAME=\"GENERATOR\" CONTENT=\"Mozilla/4.04 [en] (Win95; I) [Netscape]\">\\n\\n <TITLE>J', '', text)\n",
        "  text = re.sub(\"\\\\n\", \"\", text)\n",
        "  text = re.sub(\"||\", \"\", text)\n",
        "  text = text.replace(\"||\", \"\")\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDGKEp3RfhHT"
      },
      "outputs": [],
      "source": [
        "dt_n_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/length_comp_news.json\", lines=True)\n",
        "dt_n_sec = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/unfiltered_news_v3.json\", lines=True)\n",
        "dt_n_thi = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Tweets.csv\")\n",
        "dt_n_fou = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/Twitter_Data.csv\")\n",
        "dt_f_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/eng_literature.json\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hdP5Kd331No"
      },
      "outputs": [],
      "source": [
        "books_data = []\n",
        "with open('/content/gdrive/MyDrive/trained_models/data_for_trainig/Catch_Me_If_You_Can.txt') as f:\n",
        "  lines = f.read()\n",
        "while lines:\n",
        "  books_data.append({\"piece_of_text\": re.sub(\"||\", \"\", preproc(lines[:150])), \"headline\":\"Catch_Me_If_You_Can\"})\n",
        "      # Set the contents to everything after the first 256\n",
        "  lines = lines[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SjyUiBT31be"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/trained_models/data_for_trainig/The_Eighth_Sister_Victoria_Heward.txt') as f:\n",
        "  lines = f.read()\n",
        "while lines:\n",
        "  books_data.append({\"piece_of_text\": re.sub(\"||\", \"\", preproc(lines[:150])), \"headline\":\"The_Eighth_Sister_Victoria_Heward\"})\n",
        "      # Set the contents to everything after the first 256\n",
        "  lines = lines[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkDB5cq031lm"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/trained_models/data_for_trainig/London_John_Escott.txt') as f:\n",
        "  lines = f.read()\n",
        "while lines:\n",
        "  books_data.append({\"piece_of_text\": re.sub(\"||\", \"\", preproc(lines[:150])), \"headline\":\"London_John_Escott\"})\n",
        "      # Set the contents to everything after the first 256\n",
        "  lines = lines[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rORVgFyvl8G"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/trained_models/data_for_trainig/Hotel_Arthur_Hailey.txt') as f:\n",
        "  lines = f.read()\n",
        "while lines:\n",
        "  books_data.append({\"piece_of_text\": re.sub(\"||\", \"\", preproc(lines[:150])), \"headline\":\"Hotel_Arthur_Hailey\"})\n",
        "      # Set the contents to everything after the first 256\n",
        "  lines = lines[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwis4wFW31zg"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/trained_models/data_for_trainig/UFOs_Helen_Brooke.txt') as f:\n",
        "  lines = f.read()\n",
        "while lines:\n",
        "  books_data.append({\"piece_of_text\": re.sub(\"||\", \"\", preproc(lines[:150])), \"headline\":\"UFOs_Helen_Brooke\"})\n",
        "      # Set the contents to everything after the first 256\n",
        "  lines = lines[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHXQJx9951-J"
      },
      "outputs": [],
      "source": [
        "pieces_of_texts = []\n",
        "for text in tqdm(dt_f_one.to_dict(orient=\"records\"), total=len(dt_f_one[\"text\"])):\n",
        "  textt = preproc(text[\"text\"])\n",
        "  while textt:\n",
        "    pieces_of_texts.append({\"piece_of_text\": re.sub(\"||\", \"\", textt[:150]), \"bookname\": text[\"bookname\"]})\n",
        "        # Set the contents to everything after the first 256\n",
        "    textt = textt[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E9SpAc852An"
      },
      "outputs": [],
      "source": [
        "pieces_of_news = []\n",
        "for text in tqdm(dt_n_one.to_dict(orient=\"records\"), total=len(dt_n_one[\"news_preproc\"])):\n",
        "  textt = preproc(text[\"news_preproc\"])\n",
        "  while textt:\n",
        "    pieces_of_news.append({\"piece_of_text\": re.sub(\"||\", \"\", textt[:150]), \"headline\": text[\"headline\"]})\n",
        "        # Set the contents to everything after the first 256\n",
        "    textt = textt[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJqj4Sdw1VJp"
      },
      "outputs": [],
      "source": [
        "for text in tqdm(dt_n_thi.to_dict(orient=\"records\"), total=len(dt_n_thi[\"text\"])):\n",
        "  try:\n",
        "    textt = preproc(text[\"text\"])\n",
        "    while textt:\n",
        "      pieces_of_news.append({\"piece_of_text\": re.sub(\"||\", \"\", textt[:150]), \"headline\": \"Tweets\"})\n",
        "          # Set the contents to everything after the first 256\n",
        "      textt = textt[150:]\n",
        "  except TypeError as tpe:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKP-89UU6GOA"
      },
      "outputs": [],
      "source": [
        "for text in tqdm(dt_n_fou.to_dict(orient=\"records\"), total=len(dt_n_fou[\"clean_text\"])):\n",
        "  try:\n",
        "    textt = preproc(text[\"clean_text\"])\n",
        "    while textt:\n",
        "      pieces_of_news.append({\"piece_of_text\": re.sub(\"||\", \"\", textt[:150]), \"headline\": \"Tweets\"})\n",
        "          # Set the contents to everything after the first 256\n",
        "      textt = textt[150:]\n",
        "  except TypeError as tpe:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMbsdinUz1p_"
      },
      "outputs": [],
      "source": [
        "for text in tqdm(dt_n_sec.to_dict(orient=\"records\"), total=len(dt_n_sec[\"short_description\"])):\n",
        "  textt = preproc(text[\"short_description\"])\n",
        "  while textt:\n",
        "    pieces_of_news.append({\"piece_of_text\": re.sub(\"||\", \"\", textt[:150]), \"headline\": text[\"headline\"]})\n",
        "        # Set the contents to everything after the first 256\n",
        "    textt = textt[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f71fh0c7BX5v"
      },
      "outputs": [],
      "source": [
        "pieces_of_data = [i[\"piece_of_text\"] for i in pieces_of_texts] + [i[\"piece_of_text\"] for i in pieces_of_news] + [i[\"headline\"] for i in pieces_of_news] + [i[\"piece_of_text\"] for i in books_data]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = pd.DataFrame(ms_razbor).groupby([\"count_word_net\"]).head(15)"
      ],
      "metadata": {
        "id": "xooC-PtXV9dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USV2HlxS52DS"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "contexts_d = []\n",
        "for item in tqdm(dt.to_dict(orient=\"records\"), total = len(dt[\"punchline\"])):\n",
        "  word = item[\"lemma\"]\n",
        "  contexts = []\n",
        "  for t in pieces_of_data:\n",
        "    if word != \" \" or word != \".\" or word != \",\":\n",
        "      if str(\" \" + word) in t or str(word + \" \") in t:\n",
        "        contexts.append(t)\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "      continue\n",
        "  results.append({\"punchline\": item[\"punchline\"], \"word\": item[\"word\"],  \"contexts_count\": len(contexts)})\n",
        "  contexts_d.append({\"punchline\": item[\"punchline\"], \"count_word_net\": item[\"count_word_net\"], item[\"word\"]: contexts})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cugvn8ObSmXP"
      },
      "outputs": [],
      "source": [
        "contexted_data = pd.DataFrame(results).merge(dt, how=\"inner\", on=[\"punchline\", \"word\"])\n",
        "contexted_data_n = contexted_data[contexted_data[\"pos\"]==\"NOUN\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMCq_bSEgxas"
      },
      "source": [
        "##### Vectorizing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcJpYsBNlbVn"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "                \"bert-base-uncased\", do_lower_case=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5f113bNgwes"
      },
      "outputs": [],
      "source": [
        "def bert_embed(sent):\n",
        "  text = sent.lower().replace('\"', '') # убираем лишние кавычки и приводим к нижнему регистру\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\" # добавляем начальные метки, указываем границы анализируемого предложения\n",
        "\n",
        "  # делим предложения на токены\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  encodings = tokenizer(marked_text) # получаем начальные  представления\n",
        "\n",
        "  # Сопоставляем токены с их словарными индексами.\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  # Посмотреть на токены и индексы.\n",
        "  #for tup in zip(tokenized_text, indexed_tokens):\n",
        "  #    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "      # Оценка модели вернет различное количество объектов в зависимости от того, как она была настроена в предыдущем вызове `from_pre trained`.\n",
        "      # В этом случае, поскольку мы установили ' output_hidden_states = True, третьим элементом будут скрытые состояния из всех слоев.\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2] # берем скрытые состояния\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0) # предобрабатываем полученные скрытые состояния: объединяем последовательность тензоров вдоль новой новой размерности\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1) # Возвращает новый тензор, где удалена часть входных данных с размером 1.\n",
        "  token_embeddings = token_embeddings.permute(1,0,2) # перестановка данных для легкого изменения размеров тензора.\n",
        "\n",
        "  token_embeddings.size() # векторные представления имеют размерность 22  x 768\n",
        "  # Stores the token vectors, with shape [22 x 768]\n",
        "  token_vecs_sum = []\n",
        "\n",
        "  # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "  # For each token in the sentence...\n",
        "  for token in token_embeddings:\n",
        "\n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Sum the vectors from the last four layers. # берем векторные представления с последних 4 слоев и суммируем их.\n",
        "      sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "      # Use `sum_vec` to represent `token`.\n",
        "      token_vecs_sum.append(sum_vec)\n",
        "\n",
        "  return tokenized_text, token_vecs_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-afxjouaAx7"
      },
      "outputs": [],
      "source": [
        "def get_word_vec(tokenized_text, token_vecs_sum, text):\n",
        "  text = text.lower().replace('\"', '')\n",
        "  pretok_word = \"\"\n",
        "  ind = []\n",
        "  vec = []\n",
        "  tok_vec = []\n",
        "  for i,tok in enumerate(tokenized_text):\n",
        "    try:\n",
        "      if tok in text.split(' ')[:i+3]:\n",
        "        tok_vec.append({\"word\": tok, \"vector\": token_vecs_sum[i]}) # вектор привязываем к индексу, чтоб можно было достать\n",
        "      elif tok not in text.split(' ')[:i+3]:\n",
        "        #print(i, tok)\n",
        "        if tok == '[CLS]' or tok == '[SEP]':\n",
        "          continue\n",
        "        elif tok.startswith(\"##\"):\n",
        "          pretok_word += tok[2:]\n",
        "          ind.append(i)\n",
        "          ind = list(set(ind))\n",
        "          ind.sort()\n",
        "          vec.append(token_vecs_sum[i])\n",
        "        else:\n",
        "          pretok_word += \" \" + tok\n",
        "          ind.append(i)\n",
        "          vec.append(token_vecs_sum[i])\n",
        "        #print(pretok_word, ind,)\n",
        "        comparison = list(set([pretok_word[1:].replace(' ', '')]) & set(text.split(' ')[:i+3]))\n",
        "        #try:\n",
        "        if len(comparison) > 0:\n",
        "          word_string = \"\".join(tokenized_text[i] for i in ind).replace('#', '')\n",
        "          tok_vec.append({\"word\": word_string, \"vector\":sum(vec)/ len(vec)})    #######достаем по последнем индексу списка\n",
        "        elif len(comparison) == 0:\n",
        "          continue\n",
        "      comparison = []\n",
        "      ind = []\n",
        "      vec = []\n",
        "      pretok_word = \"\"\n",
        "      text = text.split(' ', 1)[1]\n",
        "      #print(j_text)\n",
        "    except IndexError as ie:\n",
        "      pass\n",
        "\n",
        "      return tok_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhIhHJdwhhX5"
      },
      "outputs": [],
      "source": [
        "missed_text = []\n",
        "contexts_embed = [] # для сохранения векторных представления\n",
        "words_embed= []\n",
        "for diction in tqdm(contexts_d, total=len(contexts_d)):\n",
        "  for k, list_cont in diction.items():\n",
        "    if k != \"punchline\" and k!= \"count_word_net\":\n",
        "      tokenized_text, token_vecs_sum_w = bert_embed(sent=diction[\"punchline\"])\n",
        "      tok_vec = get_word_vec(tokenized_text= tokenized_text, token_vecs_sum = token_vecs_sum_w, text=diction[\"punchline\"])\n",
        "      word_vec =[i[\"vector\"] for i in tok_vec if i[\"word\"] ==  k][0]\n",
        "      words_embed.append({\"punchline\": diction[\"punchline\"],\n",
        "                \"word\":k,\n",
        "                \"count_m\": diction[\"count_word_net\"],\n",
        "                \"word_vec\": word_vec})\n",
        "      for cont in list_cont[:500]:\n",
        "        _, token_vecs_sum = bert_embed(sent =cont)\n",
        "        b_d = {\"punchline\": diction[\"punchline\"],\n",
        "                \"word\":k,\n",
        "                \"context\": cont,\n",
        "              \"bert_cont\": sum(token_vecs_sum)/len(token_vecs_sum)} # делаем векторное представление шутки через среднее арифметическое векторных представлений BERT\n",
        "        contexts_embed.append(b_d)\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRGB_RM8c2yU"
      },
      "outputs": [],
      "source": [
        "#### сохранение данных\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "a = torch.rand(3,4,5)\n",
        "\n",
        "# save\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_words_embed_500_fin.pickle', 'wb') as handle:\n",
        "    pickle.dump(words_embed, handle)\n",
        "\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_context_embed_500_fin.pickle', 'wb') as handle:\n",
        "    pickle.dump(contexts_embed, handle)\n",
        "\n",
        "# open\n",
        "#with open('filename.pickle', 'rb') as handle:\n",
        "#    b = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JUh7oehh1rY"
      },
      "source": [
        "##### Results\n",
        "To assess the impact of a polysemic word on the overall text vector, the cosine distances between the polysemic word and a joke with deleted polysemic word, and a non-polysemic word and a joke with deleted non-polysemic word were measured. The distance between cluster centroids, and the cosine distances of the two types were analysed using Student’s t distribution. For polysemic words, p-value=0.003, for non-polysemic words pvalue<10^-6.  We can see that if a joke loses either a polysemic or a non-polysemic word, its vectorisation changes. Furthermore, in these two cases it changes differently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoFeXcJ8h_Zn"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.37.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEdrir4diJSv"
      },
      "outputs": [],
      "source": [
        "#Загрузка библиотек\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "import spacy\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epk5wmBIiSPt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJCgF7XsCoJ0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_words_embed_500_fin.pickle', 'rb') as handle:\n",
        "    words_embed = pickle.load(handle)\n",
        "\n",
        "with open('/content/gdrive/MyDrive/trained_models/filename_context_embed_500_fin.pickle', 'rb') as handle:\n",
        "    contexts_embed = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP2Kj8ZO9Taq"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from sklearn.cluster import AffinityPropagation, MeanShift\n",
        "from scipy.spatial import distance\n",
        "\n",
        "all_res = []\n",
        "count_clusters = []\n",
        "for item in tqdm(words_embed, total=len(words_embed)):\n",
        "  vecs = []\n",
        "  for it in contexts_embed:\n",
        "    if item[\"word\"] == it[\"word\"]:\n",
        "      vecs.append(it[\"bert_cont\"])\n",
        "  clustering = MeanShift(bandwidth = 30).fit([item[\"word_vec\"].numpy()] + [i.numpy() for i in vecs]) #######  проблема в снижении размерности???????\n",
        "  count_clusters.append({\"word\": item[\"word\"],\"count_cluster\":len(set(clustering.labels_)), \"count_contexts\": len(vecs) })\n",
        "  centroids = clustering.cluster_centers_\n",
        "  distances = np.empty((0,len(centroids)), float)\n",
        "  # getting points and distances\n",
        "  for center_elem in centroids:\n",
        "      for i in centroids:\n",
        "      # cdist is used to calculate the distance between center and other points\n",
        "        distances = np.append(distances, distance.cdist([center_elem],[i], 'cosine'))\n",
        "  try:\n",
        "    distances =np.delete(distances, np.where(distances==0.0))\n",
        "    distances =np.delete(distances, np.where(distances==1.1102230246251565e-16))\n",
        "    if min(distances) < 0.00000000001:\n",
        "      all_res.append({\"punchline\":item[\"punchline\"], \"word\": item[\"word\"], \"count_word_net\": item[\"count_m\"], \"min_cos_dist\":0})\n",
        "    else:\n",
        "      all_res.append({\"punchline\":item[\"punchline\"],\"word\": item[\"word\"], \"count_word_net\": item[\"count_m\"], \"min_cos_dist\":min(distances)})\n",
        "  except ValueError as ve:\n",
        "    all_res.append({\"punchline\":item[\"punchline\"], \"word\": item[\"word\"], \"min_cos_dist\":0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_4ZjMUdbza5"
      },
      "source": [
        "Количество кластеров у каждого слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoBFzmAMb9Ej"
      },
      "outputs": [],
      "source": [
        "clusters_df = pd.DataFrame(count_clusters)\n",
        "clusters_df['count_contexts'] = [1 if i==0 else i for i in clusters_df['count_contexts']]\n",
        "set(clusters_df[\"count_cluster\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC8M3KfD-QQb"
      },
      "outputs": [],
      "source": [
        "stop_symbols = [',', \".\", \";\", \":\", \"!\", \"'\", '\"', \"/\", '\\\\', '-', '–' '(', \")\", '=', '+', \"—\", '’', '#', \"?\", \"...\", \" \"]\n",
        "test_df = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/exp_triggers_test_df_bigdata_38k.csv\")\n",
        "test_df[\"label_res\"] =  test_df[\"label\"].apply(lambda x: \"joke\" if x == 0 else \"non-joke\")\n",
        "test_df[\"text\"] =  [ i.replace('...', '.').replace(\"  \", ' ') for  i in test_df[\"text\"]]\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].fillna(test_df[\"text\"])\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].apply(lambda i: str(i + \" .\") if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] =  test_df[\"text\"].apply(lambda i: None if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] = test_df[\"text\"].fillna(test_df[\"text_unpreproc\"])\n",
        "test_df[\"text\"]  = [i.lower().replace('.', ' .').replace('!', ' !').replace('?', ' ?') for i in test_df[\"text\"]]\n",
        "#test_df[\"text\"].apply(lambda i: str(i + \".\") if i[-1] not in stop_symbols else i)\n",
        "test_df= test_df.groupby([\"label\"]).head(100)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df = test_df[test_df[\"label\"] == 0].reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19C6TxQG-Qq9"
      },
      "outputs": [],
      "source": [
        "new_df = test_df.merge(pd.DataFrame(all_res), on=[\"punchline\"], how=\"inner\")\n",
        "new_df[\"joke_out\"] = [str(i[\"setup\"] + ' ' +i[\"punchline\"].replace(i[\"word\"], \"\")) for i in new_df.to_dict(orient=\"records\")]\n",
        "set(new_df[\"min_cos_dist\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0LRCgA3-REO"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "                \"bert-base-uncased\", do_lower_case=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj8HHtdJ-Rdx"
      },
      "outputs": [],
      "source": [
        "def bert_embed(sent):\n",
        "  text = sent.lower().replace('\"', '') # убираем лишние кавычки и приводим к нижнему регистру\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\" # добавляем начальные метки, указываем границы анализируемого предложения\n",
        "\n",
        "  # делим предложения на токены\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  encodings = tokenizer(marked_text) # получаем начальные  представления\n",
        "\n",
        "  # Сопоставляем токены с их словарными индексами.\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  # Посмотреть на токены и индексы.\n",
        "  #for tup in zip(tokenized_text, indexed_tokens):\n",
        "  #    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "      # Оценка модели вернет различное количество объектов в зависимости от того, как она была настроена в предыдущем вызове `from_pre trained`.\n",
        "      # В этом случае, поскольку мы установили ' output_hidden_states = True, третьим элементом будут скрытые состояния из всех слоев.\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2] # берем скрытые состояния\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0) # предобрабатываем полученные скрытые состояния: объединяем последовательность тензоров вдоль новой новой размерности\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1) # Возвращает новый тензор, где удалена часть входных данных с размером 1.\n",
        "  token_embeddings = token_embeddings.permute(1,0,2) # перестановка данных для легкого изменения размеров тензора.\n",
        "\n",
        "  token_embeddings.size() # векторные представления имеют размерность 22  x 768\n",
        "  # Stores the token vectors, with shape [22 x 768]\n",
        "  token_vecs_sum = []\n",
        "\n",
        "  # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "  # For each token in the sentence...\n",
        "  for token in token_embeddings:\n",
        "\n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Sum the vectors from the last four layers. # берем векторные представления с последних 4 слоев и суммируем их.\n",
        "      sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "      # Use `sum_vec` to represent `token`.\n",
        "      token_vecs_sum.append(sum_vec)\n",
        "\n",
        "  vector = sum(token_vecs_sum) / len(token_vecs_sum)\n",
        "  return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-o_Hh8w-R3e"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "missed = []\n",
        "cosines = []\n",
        "for diction in new_df.to_dict(orient=\"records\"):\n",
        "  word_vec = [i[\"word_vec\"] for i in words_embed if i[\"word\"]== diction[\"word\"]]\n",
        "  vector = bert_embed(sent =diction[\"joke_out\"])\n",
        "    #cos_sim = dot(vector, word_vec[\"word_vec\"])/(norm(vector)*norm(word_vec[\"word_vec\"]))\n",
        "  cos_sim =distance.cdist([word_vec[0]], [vector], \"cosine\")\n",
        "  b_d = {\"joke_out\": diction[\"joke_out\"], \"word\": diction[\"word\"] ,\n",
        "          \"cos_word_v_changed_v\": cos_sim} # делаем векторное представление шутки через среднее арифметическое векторных представлений BERT\n",
        "  cosines.append(b_d)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPzm9aUrwWKf"
      },
      "outputs": [],
      "source": [
        "new_df = new_df.merge(pd.DataFrame(cosines), on=[ \"joke_out\",\"word\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp0oXPg4JiK8"
      },
      "outputs": [],
      "source": [
        "len(new_df[new_df[\"count_word_net\"] == 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K14xVYDG1HHN"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "print(ttest_ind(a=[i for i in new_df[new_df[\"count_word_net\"] == 1][\"min_cos_dist\"]], b=[i[0][0] for  i in new_df[new_df[\"count_word_net\"] == 1][\"cos_word_v_changed_v\"]]) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.set_xticks([0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plot = sns.histplot(data=new_df[new_df[\"count_word_net\"] == 2], x=[i[0][0] for  i in new_df[new_df[\"count_word_net\"] == 2][\"cos_word_v_changed_v\"]],\n",
        "                    ax =ax, color=\"red\",  bins=10, stat='density', binrange=(0.3, 0.8))\n",
        "plot = sns.histplot(data=new_df[new_df[\"count_word_net\"] == 1], x=[i[0][0] for  i in new_df[new_df[\"count_word_net\"] == 1][\"cos_word_v_changed_v\"]], ax =ax,\n",
        "                    bins=10, stat='density', binrange=(0.3, 0.8))"
      ],
      "metadata": {
        "id": "hbxBFZAVnut_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment: syntactic probing\n",
        "\n",
        "we conducted an experiment on syntactic probing of a “bert-base-uncased” model. In the experiment, jokes’ setup and punchline were swapped, and then the jokes were submitted as input to a classifier to categorize them as humorous or non-humorous. The main corpus comprised 2,500 unchanged humorous texts, 2,500 humorous texts where setup and punchline were swapped, and 500 non-humorous texts."
      ],
      "metadata": {
        "id": "D6WpelMxcy_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading and processing data"
      ],
      "metadata": {
        "id": "-sGGNO9-agT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY2fo4OQdQgK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.37.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9x523D3dQgM"
      },
      "outputs": [],
      "source": [
        "#Загрузка библиотек\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "from tqdm import tqdm\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyeBOwSOdQgN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfUWFru8dQgN"
      },
      "outputs": [],
      "source": [
        "\n",
        "!ls /content/gdrive/MyDrive/trained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAB4dQZGdQgP"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True, output_attentions=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "                \"bert-base-uncased\", do_lower_case=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCvelNk0eTtk"
      },
      "outputs": [],
      "source": [
        "dt_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/jokes_exp_triggers_24k.json\", lines= True)\n",
        "dt_reddit_jokes = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/reddit_jokes.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ1bKzhbeTtl"
      },
      "outputs": [],
      "source": [
        "jokes = [str( i + \" \"+ u ).lower() for i,u in zip(dt_reddit_jokes[\"title\"][:62000], dt_reddit_jokes[\"body\"][:62000]) if len(str(i+ \" \" + u)) <= 256]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sekoj = [str( u + \" \"+ i).lower() for i,u in zip(dt_reddit_jokes[\"title\"][:62000], dt_reddit_jokes[\"body\"][:62000]) if len(str(i+ \" \" + u)) <= 256]"
      ],
      "metadata": {
        "id": "SbtuWoWJnyQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1cg3_hceTtm"
      },
      "outputs": [],
      "source": [
        "jokes = jokes[:5000]\n",
        "sekoj = sekoj[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_n_one = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/length_comp_news.json\", lines=True)\n",
        "dt_n_sec = pd.read_json(\"/content/gdrive/MyDrive/trained_models/data_for_trainig/unfiltered_news_v3.json\", lines=True)"
      ],
      "metadata": {
        "id": "gU5QlnRFchyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = [i for i in dt_n_one[\"headline\"] if len(i) <= 256] + [i for i in dt_n_one[\"news_preproc\"] if len(i) <= 256]"
      ],
      "metadata": {
        "id": "5TjSb1cqc0bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = news[:500]\n",
        "len(news)"
      ],
      "metadata": {
        "id": "H2CLKS2Rc4hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5cei1tdeTtm"
      },
      "outputs": [],
      "source": [
        "def bert_embed(sent):\n",
        "  text = sent.lower().replace('\"', '')\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  encodings = tokenizer(marked_text)\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "\n",
        "\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "      hidden_states = outputs[2]\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "  token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "  token_embeddings.size()\n",
        "  token_vecs_sum = []\n",
        "\n",
        "  for token in token_embeddings:\n",
        "\n",
        "      sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "      token_vecs_sum.append(sum_vec)\n",
        "\n",
        "  vector = sum(token_vecs_sum) / len(token_vecs_sum)\n",
        "  return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT-BSJineTtn"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "missed = []\n",
        "old_embedded = []\n",
        "embedded = []\n",
        "for i, joke in enumerate(jokes[:2500]):\n",
        "  vector = bert_embed(sent = joke)\n",
        "  embedded.append({\"id\":\"joke_{}\".format(i), \"text\": joke, \"label\":0, \"vector\": vector})\n",
        "for i, joke in enumerate(sekoj[:2500]):\n",
        "  vector = bert_embed(sent = joke)\n",
        "  old_embedded.append({\"id\":\"joke_{}\".format(i), \"text\": joke, \"label\":0, \"vector\": vector})\n",
        "for i,new in enumerate(news):\n",
        "  vector = bert_embed(sent = new)\n",
        "  embedded.append({\"id\":\"new_{}\".format(i),\"text\": new, \"label\":2, \"vector\": vector})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 32\n",
        "max_length =256\n",
        "class BertEmbedLayer(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentences: Array of input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentences,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\n",
        "            \"bert-base-uncased\", do_lower_case=True\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentences))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentences) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentences = self.sentences[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of text data are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentences.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "Rta6hU8TvBBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertModel\n",
        "new_model = tf.keras.models.load_model('/content/gdrive/MyDrive/trained_models/model_june_bigdata_38k_torch_no_grad.h5', custom_objects={'Custom>TFBertMainLayer':TFBertModel.from_pretrained(\"bert-base-uncased\")})"
      ],
      "metadata": {
        "id": "rxWJKS9dzcEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"joke\", 'non-joke']\n",
        "first_results = []\n",
        "for item in tqdm(embedded, total= len(embedded)):\n",
        "  sentences = np.array([item[\"text\"]])\n",
        "  test_data = BertEmbedLayer(\n",
        "      sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "  )\n",
        "\n",
        "  proba = new_model.predict(test_data[0])[0]\n",
        "  idx = np.argmax(proba)\n",
        "  proba = float('%.2f' % (proba[idx])) #%\n",
        "  pred = labels[idx]\n",
        "  first_results.append({\"id\": item[\"id\"], \"text\": item[\"text\"], \"label\": item[\"label\"],\"model_res_digit_fm\": idx, \"model_res_fm\": pred, \"model_proba_fm\": proba})"
      ],
      "metadata": {
        "id": "N7QL7wg1vteq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"joke\", 'non-joke']\n",
        "sec_results = []\n",
        "i = 0\n",
        "for item in tqdm(old_embedded[:2500], total= len(old_embedded[:2500])):\n",
        "  sentences = np.array([item[\"text\"]])\n",
        "  test_data = BertEmbedLayer(\n",
        "      sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "  )\n",
        "\n",
        "  proba = new_model.predict(test_data[0])[0]\n",
        "  idx = np.argmax(proba)\n",
        "  proba = float('%.2f' % (proba[idx])) #%\n",
        "  pred = labels[idx]\n",
        "  sec_results.append({\"id\":  item[\"id\"],\"text\": item[\"text\"], \"label\": item[\"label\"],\"model_res_digit_fm\": idx, \"model_res_fm\": pred, \"model_proba_fm\": proba})"
      ],
      "metadata": {
        "id": "hHsdQOtdvx_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cetroid = np.mean([ i[\"vector\"] for i in embedded[2500:3000]])\n",
        "new_cetroid"
      ],
      "metadata": {
        "id": "njJy8-IZv9Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_jokes = pd.DataFrame(embedded).merge(pd.DataFrame(first_results), on=[\"id\",\"text\", \"label\"], how=\"inner\")\n",
        "dt_jokes = dt_jokes[dt_jokes[\"label\"] != 2].reset_index(drop=True).reindex()\n",
        "dt_sekoj = pd.DataFrame(old_embedded).merge(pd.DataFrame(sec_results), on=[\"id\",\"text\", \"label\"], how=\"inner\")\n",
        "dt_sekoj[\"id\"] = \"punchline_setup\""
      ],
      "metadata": {
        "id": "oC07bdQapcwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_jokes[\"distance\"] =new_cetroid - dt_jokes[\"vector\"]\n",
        "dt_sekoj[\"distance\"] = new_cetroid - dt_sekoj[\"vector\"]"
      ],
      "metadata": {
        "id": "z-uuIvKiqZ-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_jokes[\"distance\"]  = [np.linalg.norm(i) for i in dt_jokes[\"distance\"]]\n",
        "dt_sekoj[\"distance\"]  = [np.linalg.norm(i) for i in dt_sekoj[\"distance\"]]"
      ],
      "metadata": {
        "id": "I1Qf_eltQQzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "both = pd.concat([dt_jokes, dt_sekoj])"
      ],
      "metadata": {
        "id": "pnCV2aKFZWO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-test\n",
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "print(ttest_ind(a=np.array([ i for i in dt_jokes[\"distance\"]]), b=np.array([i for i in dt_sekoj[\"distance\"]])))"
      ],
      "metadata": {
        "id": "VtJcVjTTs3I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(both[(both[\"model_res_digit_fm\"] == 1) & (both[\"id\"].str.contains(\"punchline_setup\")== True)])"
      ],
      "metadata": {
        "id": "_-0OGC75br68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.set_xticks([0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plot = sns.histplot(data=both[(both[\"model_res_digit_fm\"] == 0) & (both[\"id\"].str.contains(\"joke\")== True)], x=\"distance\", ax =ax, color=\"red\") # для шуток без перестановки,\n",
        "plot = sns.histplot(data=both[(both[\"model_res_digit_fm\"] == 0) & (both[\"id\"].str.contains(\"punchline_setup\")==True)], x=\"distance\", ax =ax)\n",
        "plot.set(xlabel='Distance between news centroid and \"setup-punchline\" jokes and between news centroid and \"punchline-setup\" jokes: unchanged label', ylabel='Count')"
      ],
      "metadata": {
        "id": "32MF98pKq4IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-test\n",
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "print(ttest_ind(a=np.array([ i for i in both[(both[\"model_res_digit_fm\"] == 0) & (both[\"id\"].str.contains(\"joke\")== True)][\"distance\"]]), b=np.array([i for i in both[(both[\"model_res_digit_fm\"] == 0) & (both[\"id\"].str.contains(\"punchline_setup\")==True)][\"distance\"]])))"
      ],
      "metadata": {
        "id": "Le6aUbbDcw47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.set_xticks([0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "plot = sns.histplot(data=both[(both[\"model_res_digit_fm\"] == 1) & (both[\"id\"].str.contains(\"joke\")== True)], x=\"distance\", ax =ax, color=\"red\", bins= 15) # для шуток без перестановки,\n",
        "plot = sns.histplot(data=both[(both[\"model_res_digit_fm\"] == 1) & (both[\"id\"].str.contains(\"punchline_setup\")==True)], x=\"distance\", ax =ax, bins=15)\n",
        "plot.set(xlabel='Distance between news centroid and \"setup-punchline\" jokes and between news centroid and \"punchline-setup\" jokes:changed label', ylabel='Count')"
      ],
      "metadata": {
        "id": "hm6n2Fbbrx2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-test\n",
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "print(ttest_ind(a=np.array([ i for i in both[(both[\"model_res_digit_fm\"] == 1) & (both[\"id\"].str.contains(\"joke\")== True)][\"distance\"]]), b=np.array([i for i in both[(both[\"model_res_digit_fm\"] == 1) & (both[\"id\"].str.contains(\"punchline_setup\")==True)][\"distance\"]])))"
      ],
      "metadata": {
        "id": "YObQEWSthpsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### UMAP processing\n",
        "\n",
        "\n",
        " The data was vectorised by the “bert-base-uncased” model and used as input for the classifier. Text embeddings were processed using the UMAP algorithm. Actually humorous texts recognised as such by the classifier are marked in red. Actually humorous texts recognised as non-humorous are marked in green. News texts are marked in blue."
      ],
      "metadata": {
        "id": "p0gWBnQAYy8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "qAV7FTcjhCOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#UMAP-LEARN\n",
        "import umap\n",
        "\n",
        "umap_text = umap.UMAP(n_components=2, random_state=100)\n",
        "umap_reduced = umap_text.fit_transform([i[\"vector\"]for i in embedded] + [i[\"vector\"]for i in old_embedded[:2500]])"
      ],
      "metadata": {
        "id": "2ksirV0ZhBE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqIbYpLqeTtw"
      },
      "outputs": [],
      "source": [
        "\n",
        "####Картинка UMAP\n",
        "fig, ax = plt.subplots(1,1, figsize= (13, 15))\n",
        "#ax = fig.add_subplot(111, projection='3d')\n",
        "colors = [i[\"label\"] for i in embedded] + [i[\"model_res_digit_fm\"] for i in sec_results]\n",
        "ax.scatter(umap_reduced[:, 0], umap_reduced[:, 1], c=[\"red\" if i == 0 else \"blue\" if i==2 else \"green\" for i in colors], ) # train_b[:, 0], train_b[:, 1], c=list(k_means_bert) - нужно заменить, чтобы получить виз-цию результатов для Берта.\n",
        "\n",
        "\n",
        "#plt.xlim(xmin=0, xmax=30)\n",
        "# only show 100 - 1600 on y-axis.\n",
        "#plt.ylim(ymin=0, ymax=30)\n",
        "\n",
        "ax.set_xlabel('$X$')\n",
        "ax.set_ylabel('$Y$')\n",
        "plt.title(\"График распределения шуток и не-шуток в векторном пространстве\")\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.4,\n",
        "                    hspace=0.4)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig(fname = \"data_200_color.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUlsvha9eTty"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2YaHJdCCdOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw5Qeqn_gx_9"
      },
      "source": [
        "#### Experiments with eliminating random words from text\n",
        "\n",
        "In this experiment, we eliminated certain text fragments identified as potentially significant semantic concepts from all texts. This approach is more relevant for jokes than for news or fiction, since the latter tend to be ordinary non-humorous texts from the start (Raskin V., 1984). The results are presented for a part of the validation corpus comprising 100 jokes. Following the initial assessment by the model, the validation dataset was subjected to a series of experimental modifications to find out after which changes jokes cease to be humorous and turn into ordinary texts. Text fragments were eliminated on the basis of their potential impact on the semantic meaning in different parts of the texts, especially humorous ones. The working unit was a token: a word or punctuation mark. In the course of designing the experiments, tokens’ positions relative to the sequence structure, lexical expression, and syntactic relations were taken into account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggC5AXeXNlOo"
      },
      "source": [
        "##### Load main dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSvNH4EgKxA9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px9i6NHu6sCM"
      },
      "outputs": [],
      "source": [
        "# Load, explore and plot data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split# Text pre-processing\n",
        "import tensorflow as tf\n",
        "#tf.config.run_functions_eagerly(True)\n",
        "from transformers import BertTokenizer,TFBertModel\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUO8uCz_BikJ"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O3-QTWz0ChH"
      },
      "outputs": [],
      "source": [
        "\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI_e3EPx6fCx"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LucPssk7zlzf"
      },
      "outputs": [],
      "source": [
        "max_length = 256  # Maximum length of input sentence to the model.\n",
        "batch_size = 32\n",
        "\n",
        "# Labels in our dataset.\n",
        "#labels_sec = list(set(dfnj_sec[\"label\"]))\n",
        "#stop_w = stopwords.words('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLDA00Fvzgug"
      },
      "outputs": [],
      "source": [
        "class BertEmbedLayer(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentences: Array of input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentences,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\n",
        "            \"bert-base-uncased\", do_lower_case=True\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentences))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentences) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentences = self.sentences[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of text data are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentences.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejpxNkerD2dh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDdey2BoEe9p"
      },
      "outputs": [],
      "source": [
        "\n",
        "!ls /content/gdrive/MyDrive/trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuCd2i51CrVL"
      },
      "outputs": [],
      "source": [
        "new_model = tf.keras.models.load_model('/content/gdrive/MyDrive/trained_models/model_june_bigdata_38k_torch_no_grad.h5', custom_objects={'TFBertModel':TFBertModel.from_pretrained(\"bert-base-uncased\")})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rG7nCiw3KMP"
      },
      "outputs": [],
      "source": [
        "stop_symbols = [',', \".\", \";\", \":\", \"!\", \"'\", '\"', \"/\", '\\\\', '-', '–' '(', \")\", '=', '+', \"—\", '’', '#', \"?\", \"...\", \" \"]\n",
        "test_df = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/exp_triggers_test_df_bigdata_38k.csv\")\n",
        "test_df[\"label_res\"] =  test_df[\"label\"].apply(lambda x: \"joke\" if x == 0 else \"non-joke\")\n",
        "test_df[\"text\"] =  [ i.replace('...', '.').replace(\"  \", ' ') for  i in test_df[\"text\"]]\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].fillna(test_df[\"text\"])\n",
        "test_df[\"text_unpreproc\"] = test_df[\"text_unpreproc\"].apply(lambda i: str(i + \" .\") if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] =  test_df[\"text\"].apply(lambda i: None if i[-1] not in stop_symbols else i)\n",
        "test_df[\"text\"] = test_df[\"text\"].fillna(test_df[\"text_unpreproc\"])\n",
        "test_df[\"text\"]  = [i.lower().replace('.', ' .').replace('!', ' !').replace('?', ' ?') for i in test_df[\"text\"]]\n",
        "#test_df[\"text\"].apply(lambda i: str(i + \".\") if i[-1] not in stop_symbols else i)\n",
        "y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=2)\n",
        "test_df= test_df.groupby([\"label\"]).head(100)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k4qSn7D790v"
      },
      "outputs": [],
      "source": [
        "test_data = BertEmbedLayer(\n",
        "    test_df[\"text\"].values.astype(\"str\"),\n",
        "    y_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0JFkgQpFdZR"
      },
      "outputs": [],
      "source": [
        "labels = [\"joke\", 'non-joke']\n",
        "first_results = []\n",
        "for item in tqdm(test_df.to_dict(orient=\"records\"), total= len(test_df.to_dict(orient=\"records\"))):\n",
        "  sentences = np.array([item[\"text\"]])\n",
        "  test_data = BertEmbedLayer(\n",
        "      sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "  )\n",
        "\n",
        "  proba = new_model.predict(test_data[0])[0]\n",
        "  idx = np.argmax(proba)\n",
        "  proba = float('%.2f' % (proba[idx])) #%\n",
        "  pred = labels[idx]\n",
        "  first_results.append({\"id\":item[\"id\"], \"text\": item[\"text\"], \"text_unpreproc\": item[\"text_unpreproc\"], \"label\": item[\"label\"], \"label_res\": item[\"label_res\"], \"model_res_digit_fm\": idx, \"model_res_fm\": pred, \"model_proba_fm\": proba})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gZ7I5dCTdU4"
      },
      "outputs": [],
      "source": [
        "df_fr = pd.DataFrame(first_results)\n",
        "df_fr[\"id\"] = [\"sfj5fkjf_{}_{}\".format(i,l) for i, l in enumerate(df_fr[\"label_res\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU_Ltr-qFqLf"
      },
      "outputs": [],
      "source": [
        "classes = [0, 1]\n",
        "con_mat =tf.math.confusion_matrix(labels=df_fr[\"label\"], predictions=df_fr[\"model_res_digit_fm\"]).numpy()\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "                     index = labels,\n",
        "                     columns = labels)\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ002P8jQ7KZ"
      },
      "outputs": [],
      "source": [
        "df_fr.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_triggers_test_df_bigdata_38k_df_fr.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUBS52uoFycG"
      },
      "outputs": [],
      "source": [
        "df_fr = pd.read_csv(\"/content/gdrive/MyDrive/trained_models/exp_triggers_test_df_bigdata_38k_df_fr.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKmXVB5_OHkK"
      },
      "source": [
        "##### Words' elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_-xPQoY8NH7"
      },
      "source": [
        "###### Eliminating tokens at the end of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0cnjtIbO0SN"
      },
      "outputs": [],
      "source": [
        "# Тест 1: выкидываем с конца\n",
        "\n",
        "last_word_l = []\n",
        "last_two_words_l = []\n",
        "last_three_words_l = []\n",
        "for item in tqdm(df_fr.to_dict(orient=\"records\"), total = len(df_fr.to_dict(orient=\"records\"))):\n",
        "  tokenized_text = nltk.word_tokenize(item[\"text\"].lower())\n",
        "  tokenized_text = [w for w in tokenized_text]\n",
        "  last_word = tokenized_text[-2] # меняем вместо единицы на -2, чтобы у нас оставались знаки препинания\n",
        "  last_two_words = \" \".join([tokenized_text[len(tokenized_text) - 3], tokenized_text[-2]])\n",
        "  last_three_words =  \" \".join([tokenized_text[len(tokenized_text) - 4], tokenized_text[len(tokenized_text) - 3], tokenized_text[-2]])\n",
        "  last_word_l.append({\n",
        "                      \"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_last_word\": \" \".join(tokenized_text).replace(last_word, '')})\n",
        "  last_two_words_l.append({\"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_last_two_words\": \" \".join(tokenized_text).replace(last_two_words, '')})\n",
        "  last_three_words_l.append({\"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_last_three_words\": \" \".join(tokenized_text).replace(last_three_words, '')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laFnzZVEQDxD"
      },
      "outputs": [],
      "source": [
        "df_fr_last = df_fr.merge(pd.DataFrame(last_word_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(last_two_words_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(last_three_words_l), on = [\"text\", \"label\"], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_VfEVt2Bl0i"
      },
      "outputs": [],
      "source": [
        "def get_model_proba_strip_words(count_w):\n",
        "  cutoff_results = []\n",
        "  for item in tqdm(df_fr_last.to_dict(orient=\"records\"), total= len(df_fr_last.to_dict(orient=\"records\"))):\n",
        "    sentences = np.array([item[count_w]])\n",
        "    test_data = BertEmbedLayer(\n",
        "        sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = new_model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = proba[idx]\n",
        "    pred = labels[idx]\n",
        "    cutoff_results.append({\"id\": item[\"id\"],\n",
        "                           \"text\": item[\"text\"],\n",
        "                            \"strip_words\": item[count_w],\n",
        "                            \"model_res_digit\": idx,\n",
        "                            \"model_res\": pred,\n",
        "                            \"model_proba\": round(proba, 4),\n",
        "                           \"type_cut_off_words\": count_w})\n",
        "  return cutoff_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rPTt83CcBeu"
      },
      "outputs": [],
      "source": [
        "list_strip_words = [\"strip_last_word\", \"strip_last_two_words\", \"strip_last_three_words\"]\n",
        "last_three_words = get_model_proba_strip_words(count_w=\"strip_last_three_words\")\n",
        "last_two_words = get_model_proba_strip_words(count_w=\"strip_last_two_words\")\n",
        "last_one_word = get_model_proba_strip_words(count_w=\"strip_last_word\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rioW2M79OQVU"
      },
      "outputs": [],
      "source": [
        "all_str_df = pd.concat([pd.DataFrame(last_three_words), pd.DataFrame(last_two_words), pd.DataFrame(last_one_word)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4TkWL_sdAgd"
      },
      "outputs": [],
      "source": [
        "all_str_df =all_str_df.merge(all_str_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "all_str_df = all_str_df.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2azKpzZugWWa"
      },
      "outputs": [],
      "source": [
        "del df_fr_last[\"strip_last_word\"]\n",
        "del df_fr_last[\"strip_last_two_words\"]\n",
        "del df_fr_last[\"strip_last_three_words\"]\n",
        "\n",
        "df_fr_last = df_fr_last.merge(all_str_df, on=[\"id\", \"text\"], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn8RoXxJ0OSP"
      },
      "outputs": [],
      "source": [
        "df_fr_last = df_fr_last.sort_values(by=[\"label_res\"], ascending= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fmm1KP88hUA"
      },
      "source": [
        "###### Eliminating at the beginning of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqRNwZHv8vGm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "first_word_l = []\n",
        "first_two_words_l = []\n",
        "first_three_words_l = []\n",
        "for item in tqdm(df_fr.to_dict(orient=\"records\"), total = len(df_fr.to_dict(orient=\"records\"))):\n",
        "  try:\n",
        "    tokenized_text = nltk.word_tokenize(item[\"text\"].lower())\n",
        "    tokenized_text = [w for w in tokenized_text if w not in stop_symbols]\n",
        "    first_word = tokenized_text[0]\n",
        "    first_two_words = \" \".join([tokenized_text[0], tokenized_text[1]])\n",
        "    first_three_words =  \" \".join([tokenized_text[0], tokenized_text[1], tokenized_text[2]])\n",
        "  except IndexError as ie:\n",
        "    first_three_words =  \" \".join([tokenized_text[0], tokenized_text[1]])\n",
        "  first_word_l.append({\n",
        "                      \"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_first_word\": \" \".join(tokenized_text).replace(first_word, '')})\n",
        "  first_two_words_l.append({\"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_first_two_words\": \" \".join(tokenized_text).replace(first_two_words, '')})\n",
        "  first_three_words_l.append({\"text\":item[\"text\"],\n",
        "                      \"label\": item[\"label\"],\n",
        "                      \"strip_first_three_words\": \" \".join(tokenized_text).replace(first_three_words, '')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMCoyA-Q8vQM"
      },
      "outputs": [],
      "source": [
        "df_fr_fir = df_fr.merge(pd.DataFrame(first_word_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(first_two_words_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(first_three_words_l), on = [\"text\", \"label\"], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMAm2Qps8vYi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model_proba_strip_words(count_w):\n",
        "  cutoff_results = []\n",
        "  for item in tqdm(df_fr_fir.to_dict(orient=\"records\"), total= len(df_fr_fir.to_dict(orient=\"records\"))):\n",
        "    sentences = np.array([item[count_w]])\n",
        "    test_data = BertEmbedLayer(\n",
        "        sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = new_model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = proba[idx]\n",
        "    pred = labels[idx]\n",
        "    cutoff_results.append({\"id\": item[\"id\"],\n",
        "                           \"text\": item[\"text\"],\n",
        "                            \"strip_words\": item[count_w],\n",
        "                            \"model_res_digit\": idx,\n",
        "                            \"model_res\": pred,\n",
        "                            \"model_proba\": proba,\n",
        "                           \"count_cut_off_words\": count_w})\n",
        "  return cutoff_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWDTbwmN8vgl"
      },
      "outputs": [],
      "source": [
        "list_strip_words = [\"strip_first_word\", \"strip_first_two_words\", \"strip_first_three_words\"]\n",
        "first_three_words = get_model_proba_strip_words(count_w=\"strip_first_three_words\")\n",
        "first_two_words = get_model_proba_strip_words(count_w=\"strip_first_two_words\")\n",
        "first_one_word = get_model_proba_strip_words(count_w=\"strip_first_word\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKzi_ctFDt1G"
      },
      "outputs": [],
      "source": [
        "all_str_df = pd.concat([pd.DataFrame(first_three_words), pd.DataFrame(first_two_words), pd.DataFrame(first_one_word)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVyVH3lvlglH"
      },
      "outputs": [],
      "source": [
        "all_str_df =all_str_df.merge(all_str_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "all_str_df = all_str_df.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU-nzo-r8voM"
      },
      "outputs": [],
      "source": [
        "del df_fr_fir[\"strip_first_word\"]\n",
        "del df_fr_fir[\"strip_first_two_words\"]\n",
        "del df_fr_fir[\"strip_first_three_words\"]\n",
        "\n",
        "\n",
        "df_fr_fir = df_fr_fir.merge(all_str_df, on=[\"id\", \"text\"], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZJnlcxQ1w5M"
      },
      "outputs": [],
      "source": [
        "df_fr_fir = df_fr_fir.sort_values(by=[\"label_res\"], ascending= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVXnrpbFqxHc"
      },
      "source": [
        "###### Eliminating in the middle of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8vTz1_erOdQ"
      },
      "outputs": [],
      "source": [
        "middle_word_l = []\n",
        "middle_two_words_l = []\n",
        "middle_three_words_l = []\n",
        "for item in tqdm(df_fr.to_dict(orient=\"records\"), total = len(df_fr.to_dict(orient=\"records\"))):\n",
        "  try:\n",
        "      tokenized_text = nltk.word_tokenize(item[\"text\"].lower())\n",
        "      tokenized_text = [w for w in tokenized_text if w not in stop_symbols]\n",
        "      middle_word = tokenized_text[math.ceil(len(tokenized_text) / 2)]\n",
        "      middle_two_words = \" \".join([tokenized_text[math.ceil(len(tokenized_text) / 2)], tokenized_text[math.ceil(len(tokenized_text) / 2) + 1]])\n",
        "      middle_three_words =  \" \".join([tokenized_text[math.ceil(len(tokenized_text) / 2) - 1], tokenized_text[math.ceil(len(tokenized_text) / 2)], tokenized_text[math.ceil(len(tokenized_text) / 2) + 1]])\n",
        "      middle_word_l.append({\n",
        "                          \"text\":item[\"text\"],\n",
        "                          \"label\": item[\"label\"],\n",
        "                          \"strip_middle_word\": \" \".join(tokenized_text).replace(middle_word, '')})\n",
        "      middle_two_words_l.append({\"text\":item[\"text\"],\n",
        "                          \"label\": item[\"label\"],\n",
        "                          \"strip_middle_two_words\": \" \".join(tokenized_text).replace(middle_two_words, '')})\n",
        "      middle_three_words_l.append({\"text\":item[\"text\"],\n",
        "                          \"label\": item[\"label\"],\n",
        "                          \"strip_middle_three_words\": \" \".join(tokenized_text).replace(middle_three_words, '')})\n",
        "  except IndexError as ie:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTRFyi0GvgZw"
      },
      "outputs": [],
      "source": [
        "df_fr_mid = df_fr.merge(pd.DataFrame(middle_word_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(middle_two_words_l), on = [\"text\", \"label\"], how='inner').merge(pd.DataFrame(middle_three_words_l), on = [\"text\", \"label\"], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpWqrE4drOg2"
      },
      "outputs": [],
      "source": [
        "labels = [\"joke\", 'non-joke']\n",
        "def get_model_proba_strip_words(count_w):\n",
        "  cutoff_results = []\n",
        "  for item in tqdm(df_fr_mid.to_dict(orient=\"records\"), total= len(df_fr_mid.to_dict(orient=\"records\"))):\n",
        "    sentences = np.array([item[count_w]])\n",
        "    test_data = BertEmbedLayer(\n",
        "        sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = new_model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = proba[idx]\n",
        "    pred = labels[idx]\n",
        "    cutoff_results.append({\"id\": item[\"id\"],\n",
        "                           \"text\": item[\"text\"],\n",
        "                            \"strip_words\": item[count_w],\n",
        "                            \"model_res_digit\": idx,\n",
        "                            \"model_res\": pred,\n",
        "                            \"model_proba\": proba,\n",
        "                           \"count_cut_off_words\": count_w})\n",
        "  return cutoff_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ9k4sOErO80"
      },
      "outputs": [],
      "source": [
        "list_strip_words = [\"strip_middle_word\", \"strip_middle_two_words\", \"strip_middle_three_words\"]\n",
        "middle_three_words = get_model_proba_strip_words(count_w=\"strip_middle_three_words\")\n",
        "middle_two_words = get_model_proba_strip_words(count_w=\"strip_middle_two_words\")\n",
        "middle_one_word = get_model_proba_strip_words(count_w=\"strip_middle_word\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3V5tbebhMB8"
      },
      "outputs": [],
      "source": [
        "all_str_df = pd.concat([pd.DataFrame(middle_three_words), pd.DataFrame(middle_two_words), pd.DataFrame(middle_one_word)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwZA03korPJ5"
      },
      "outputs": [],
      "source": [
        "all_str_df =all_str_df.merge(all_str_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "all_str_df = all_str_df.rename(columns={\"model_proba\": \"worst_proba\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kP_pA5wrPSP"
      },
      "outputs": [],
      "source": [
        "del df_fr_mid[\"strip_middle_word\"]\n",
        "del df_fr_mid[\"strip_middle_two_words\"]\n",
        "del df_fr_mid[\"strip_middle_three_words\"]\n",
        "\n",
        "df_fr_mid = df_fr_mid.merge(all_str_df, on=[\"id\", \"text\"], how='inner')\n",
        "df_fr_mid = df_fr_mid.sort_values(by=[\"id\", \"text\", \"model_proba_fm\", \"worst_proba\"], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNrOZcpc2CEF"
      },
      "outputs": [],
      "source": [
        "df_fr_mid = df_fr_mid.sort_values(by=[\"label_res\"], ascending= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### SpaCy Preprocessing"
      ],
      "metadata": {
        "id": "2OrLnxI5ge16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzQErF6nsAqD"
      },
      "outputs": [],
      "source": [
        "!pip install en_core_web_sm\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoK-aFRA2ANj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blKO_X6e1_Q7"
      },
      "outputs": [],
      "source": [
        "!ls /content/gdrive/MyDrive/trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GEnmGSS9WdZ"
      },
      "outputs": [],
      "source": [
        "del test_df[test_df.columns[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k4s8goPHz1K"
      },
      "outputs": [],
      "source": [
        "ling_df = df_fr.merge(test_df, on=[\"text\", \"text_unpreproc\", \"label\", \"label_res\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Frsa664Zxi0"
      },
      "outputs": [],
      "source": [
        "spacy_model = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxWlVdaZj7g"
      },
      "source": [
        "Основные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXT_WkKUZoDh"
      },
      "outputs": [],
      "source": [
        "def get_model_proba_setup_punch(setup, punchline):\n",
        "  labels = [\"joke\", \"non-joke\"]\n",
        "  cutoff_results = []\n",
        "  for item in tqdm(ling_df.to_dict(orient=\"records\"), total= len(ling_df.to_dict(orient=\"records\"))):\n",
        "    sentences = np.array([\" \".join([item[setup], item[punchline]])])\n",
        "    test_data = BertEmbedLayer(\n",
        "        sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = new_model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = proba[idx]\n",
        "    pred = labels[idx]\n",
        "    cutoff_results.append({\"id\": item[\"id\"],\n",
        "                           \"text\": item[\"text\"],\n",
        "                           \"label\": item[\"label\"],\n",
        "                           \"label_res\": item[\"label_res\"],\n",
        "                            \"model_res_digit_fm\": item[\"model_res_digit_fm\"],\n",
        "                            \"model_res_fm\": item[\"model_res_fm\"],\n",
        "                           \"model_proba_fm\": item[\"model_proba_fm\"],\n",
        "                            \"text_out\": \" \".join([item[setup], item[punchline]]),\n",
        "                           \"type_text_out\": \"_\".join([setup, punchline]),\n",
        "                            \"model_res_digit\": idx,\n",
        "                            \"model_res\": pred,\n",
        "                            \"model_proba\": proba,\n",
        "                           \"text_unpreproc\": item[\"text_unpreproc\"]})\n",
        "  return cutoff_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltbN6GtqZtvt"
      },
      "outputs": [],
      "source": [
        "def get_model_proba_text(text):\n",
        "  labels = [\"joke\", \"non-joke\"]\n",
        "  cutoff_results = []\n",
        "  for item in tqdm(ling_df.to_dict(orient=\"records\"), total= len(ling_df.to_dict(orient=\"records\"))): #ling_df\n",
        "    sentences = np.array([item[text]])\n",
        "    test_data = BertEmbedLayer(\n",
        "        sentences, labels=labels, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = new_model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = proba[idx]\n",
        "    pred = labels[idx]\n",
        "    cutoff_results.append({\"id\": item[\"id\"],\n",
        "                           \"text\": item[\"text\"],\n",
        "                           \"label\": item[\"label\"],\n",
        "                           \"label_res\": item[\"label_res\"],\n",
        "                            \"model_res_digit_fm\": item[\"model_res_digit_fm\"],\n",
        "                            \"model_res_fm\": item[\"model_res_fm\"],\n",
        "                           \"model_proba_fm\": item[\"model_proba_fm\"],\n",
        "                            \"changed_text\": item[text] , #text_out\n",
        "                           \"type_text_out\": text,\n",
        "                            \"model_res_digit\": idx,\n",
        "                            \"model_res\": pred,\n",
        "                            \"model_proba\": proba,\n",
        "                           \"text_unpreproc\": item[\"text_unpreproc\"]})\n",
        "  return cutoff_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWjy3i887_1J"
      },
      "source": [
        "###### Eliminating a single noun/proper noun/pronoun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwstTbNC1e9n"
      },
      "outputs": [],
      "source": [
        "def clean_first_noun(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  tokenized_text = [token.text for token in doc]\n",
        "  clean_text = []\n",
        "  for i, token in enumerate(doc):\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.pos_ == 'NOUN' or  token.pos_ == 'PROPN':\n",
        "        del tokenized_text[i]\n",
        "        break\n",
        "      elif token.pos_ != 'NOUN' or  token.pos_ != 'PROPN':\n",
        "        continue\n",
        "  clean_text = \" \".join(tokenized_text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox7ghTPd2RdU"
      },
      "outputs": [],
      "source": [
        "ling_df_fr = ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Osn-1eX8hm-"
      },
      "outputs": [],
      "source": [
        "ling_df_fr[\"setup_out\"] = [clean_first_noun(s) for s in ling_df_fr[\"setup\"]]\n",
        "ling_df_fr[\"punchline_out\"] = [clean_first_noun(s) for s in ling_df_fr[\"punchline\"]]\n",
        "ling_df_fr[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_fr[\"setup_out\"], ling_df_fr[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPxt8HzZ1fZw"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zMyUEIZRJmC"
      },
      "outputs": [],
      "source": [
        "res_df_onen =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_onen = res_df_onen.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRsos7kqQ58c"
      },
      "outputs": [],
      "source": [
        "res_df_onen = res_df_onen.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ135g0NbBqi"
      },
      "outputs": [],
      "source": [
        "res_df_onen.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_one_noun_1000.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHPOz7JrsRwL"
      },
      "source": [
        "###### Eliminating all nouns/proper names/pronouns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZMzZxFNoVbb"
      },
      "outputs": [],
      "source": [
        "ling_df_sec= ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLXAI7_5_SPb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def non_joke_division(news):\n",
        "  jokes_missed = []\n",
        "  news = str(news)\n",
        "  setup = ''\n",
        "  punchline= ''\n",
        "  if \",\" in news:\n",
        "      joke_division = news.rsplit(\",\", 1)\n",
        "      setup =  joke_division[0]\n",
        "      punchline = joke_division[1]\n",
        "  elif \"?\" in news:\n",
        "      joke_division = news.rsplit(\"?\", 1)\n",
        "      setup =  joke_division[0]\n",
        "      punchline = joke_division[1]\n",
        "  elif \".\" in news: #and news.rsplit(\".\", 1)[1] != '': #### ПРОБЛЕМА С ДВУМЯ ПРЕДЛОЖЕНИЯМИ\n",
        "      if news.count('.') > 1:\n",
        "          joke_division = news.rsplit(\" . \", 2)\n",
        "          setup =  joke_division[0]\n",
        "          punchline = joke_division[1]\n",
        "      elif news.count('.') == 1 and news.rsplit(\".\", 1)[1] != ' ':\n",
        "          joke_division = news.rsplit(\" . \", 1)\n",
        "          setup =  joke_division[0]\n",
        "          punchline = joke_division[1]\n",
        "      elif news.count('.') == 1 and news.rsplit(\".\", 1)[1] == ' ':\n",
        "          tokenized_text = nltk.word_tokenize(news.lower())\n",
        "          tokenized_text = [w for w in tokenized_text if w not in stop_symbols]\n",
        "          setup = \" \".join(tokenized_text[:math.ceil(len(tokenized_text) / 2)])\n",
        "          punchline = \" \".join(tokenized_text[math.ceil(len(tokenized_text) / 2):])\n",
        "  else:\n",
        "      tokenized_text = nltk.word_tokenize(news.lower())\n",
        "      tokenized_text = [w for w in tokenized_text if w not in stop_symbols]\n",
        "      setup = \" \".join(tokenized_text[:math.ceil(len(tokenized_text) / 2)])\n",
        "      punchline = \" \".join(tokenized_text[math.ceil(len(tokenized_text) / 2):])\n",
        "  return setup, punchline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDsHNsF01fxL"
      },
      "outputs": [],
      "source": [
        "def clean_all_nouns(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  #tokenized_text = [token.text for token in doc]\n",
        "  clean_text_l = []\n",
        "  for token in doc:\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.pos_ == 'NOUN' or token.pos_ == 'PROPN':\n",
        "        continue\n",
        "      elif token.pos_ != 'NOUN' or token.pos_ != 'PROPN':\n",
        "        clean_text_l.append(token.text)\n",
        "  clean_text = \" \".join(clean_text_l)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkSYIa1r1f4I"
      },
      "outputs": [],
      "source": [
        "ling_df_sec[\"setup_out\"] = [clean_all_nouns(s) for s in ling_df_sec[\"setup\"]]\n",
        "ling_df_sec[\"punchline_out\"] = [clean_all_nouns(s) for s in ling_df_sec[\"punchline\"]]\n",
        "ling_df_sec[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_sec[\"setup_out\"], ling_df_sec[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LTHzRmHtiwh"
      },
      "outputs": [],
      "source": [
        "res_df_al_ns = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlqNvjtxti72"
      },
      "outputs": [],
      "source": [
        "res_df_all_n =res_df_al_ns.merge(res_df_al_ns.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_all_n = res_df_all_n.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhrAPWrCaxg3"
      },
      "outputs": [],
      "source": [
        "res_df_all_n = res_df_all_n.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_eO-sfxcEDf"
      },
      "outputs": [],
      "source": [
        "res_df_all_n.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_all_noun_1000.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4whWXP9P9lI"
      },
      "source": [
        "Мера обманутости модели при подаче измененного типа текста\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7ZS9PqDX6c"
      },
      "source": [
        "###### Eliminating a single verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYtg50uV3Oqj"
      },
      "outputs": [],
      "source": [
        "ling_df_th = ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz5CSYvMI-fu"
      },
      "outputs": [],
      "source": [
        "def clean_first_verb(text):\n",
        "  doc = spacy_model(text)\n",
        "  tokenized_text = [token.text for token in doc]\n",
        "  clean_text = []\n",
        "  for i, token in enumerate(doc):\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.pos_ == 'VERB' or token.pos_ == 'AUX':\n",
        "        del tokenized_text[i]\n",
        "        break\n",
        "      elif token.pos_ != 'VERB' or token.pos_ != 'AUX':\n",
        "        continue\n",
        "  clean_text = \" \".join(tokenized_text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKF60NtVLFQb"
      },
      "outputs": [],
      "source": [
        "ling_df_th[\"setup_out\"] = [clean_first_verb(s) for s in ling_df_th[\"setup\"]]\n",
        "ling_df_th[\"punchline_out\"] = [clean_first_verb(s) for s in ling_df_th[\"punchline\"]]\n",
        "ling_df_th[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_th[\"setup_out\"], ling_df_th[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2erqrtzNb2kB"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqiAPJ7QLoQk"
      },
      "outputs": [],
      "source": [
        "res_df_onev =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_onev = res_df_onev.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP9PoBbEI-i-"
      },
      "outputs": [],
      "source": [
        "res_df_onev = res_df_onev.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO681nVifBdj"
      },
      "outputs": [],
      "source": [
        "res_df_onev.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_one_v_1000.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5R6bqczImGe"
      },
      "source": [
        "###### Eliminating all verbs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKoATKLPfplg"
      },
      "outputs": [],
      "source": [
        "ling_df_thh= ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7PXoMdQGtbQ"
      },
      "outputs": [],
      "source": [
        "def clean_all_verbs(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  #tokenized_text = [token.text for token in doc]\n",
        "  clean_text_l = []\n",
        "  for token in doc:\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.pos_ == 'VERB' or token.pos_ == 'AUX':\n",
        "        continue\n",
        "      elif token.pos_ != 'VERB' or token.pos_ != 'AUX':\n",
        "        clean_text_l.append(token.text)\n",
        "  clean_text = \" \".join(clean_text_l)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztTc7gbiJBCj"
      },
      "outputs": [],
      "source": [
        "ling_df_thh[\"setup_out\"] = [clean_all_verbs(s) for s in ling_df_thh[\"setup\"]]\n",
        "ling_df_thh[\"punchline_out\"] = [clean_all_verbs(s) for s in ling_df_thh[\"punchline\"]]\n",
        "ling_df_thh[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_thh[\"setup_out\"], ling_df_thh[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5afLVWfGtgZ"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvv3Z3digFHP"
      },
      "outputs": [],
      "source": [
        "res_df_allv =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_allv = res_df_allv.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxGAvvaFgFWF"
      },
      "outputs": [],
      "source": [
        "res_df_allv = res_df_allv.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGIgeX-ccfY"
      },
      "source": [
        "###### Eliminating a single noun phrase with elements linked by syntactic relations nsubj (nominal subject), expl (pleonastic nominations), nmod (attribute or complement in the genitive case), or appos (dependent common noun for modifying the first noun)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSROKWiqczBr"
      },
      "outputs": [],
      "source": [
        "ling_df_for= ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc7BUbR3hFZH"
      },
      "outputs": [],
      "source": [
        "def clean_first_couple_n_v(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  tokenized_text = [token.text for token in doc]\n",
        "  clean_text = []\n",
        "\n",
        "  for i, token in enumerate(doc):\n",
        "    try:\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.dep_ == 'nsubj' and token.head.pos_=='VERB' and token.head.text in tokenized_text:\n",
        "        try:\n",
        "          del tokenized_text[i]\n",
        "          tokenized_text.remove(token.head.text)\n",
        "          break\n",
        "        except IndexError as ie:\n",
        "          continue\n",
        "      elif token.dep_ != 'nsubj':\n",
        "        if token.dep_ == 'nmod' or token.dep_ == 'expl' or token.dep_ == 'appos': # рассмотреть отдельно и со всеми вместе\n",
        "          try:\n",
        "            del tokenized_text[i]\n",
        "            tokenized_text.remove(token.head.text)\n",
        "          except IndexError as ie:\n",
        "            continue\n",
        "        if token.dep_ != 'nmod' or token.dep_ != 'expl' or token.dep_ != 'appos':\n",
        "          continue\n",
        "    except ValueError as ver:\n",
        "      continue\n",
        "  clean_text = \" \".join(tokenized_text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90OGUXmtczLk"
      },
      "outputs": [],
      "source": [
        "ling_df_for[\"setup_out\"]= [clean_first_couple_n_v(s) for s in ling_df_for[\"setup\"]]\n",
        "ling_df_for[\"punchline_out\"] = [clean_first_couple_n_v(s) for s in ling_df_for[\"punchline\"] if len(s)]\n",
        "ling_df_for[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_for[\"setup_out\"], ling_df_for[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpMcGwcCczQV"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxZXxDvWh-hB"
      },
      "outputs": [],
      "source": [
        "res_df_nv =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_nv = res_df_nv.rename(columns={\"model_proba\": \"worst_proba\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19nmOLiJh-pN"
      },
      "outputs": [],
      "source": [
        "res_df_nv = res_df_nv.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VGS4VipiG4l"
      },
      "outputs": [],
      "source": [
        "res_df_nv.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_nsubj.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwkLFOaTwQZ-"
      },
      "source": [
        "###### Eliminating a single phrase with elements linked by syntactic relations nsubj (nominal subject)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6zirrDQwQaB"
      },
      "outputs": [],
      "source": [
        "ling_df_for= ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG1v7BeSwQaD"
      },
      "outputs": [],
      "source": [
        "def clean_first_couple_n_v(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  tokenized_text = [token.text for token in doc]\n",
        "  clean_text = []\n",
        "  for i, token in enumerate(doc):\n",
        "    try:\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.dep_ == 'nsubj' and token.head.pos_=='VERB' and token.head.text in tokenized_text:\n",
        "        del tokenized_text[i]\n",
        "        tokenized_text.remove(token.head.text)\n",
        "        break\n",
        "      elif token.dep_ != 'nsubj':\n",
        "        continue\n",
        "    except ValueError as ver:\n",
        "      continue\n",
        "  clean_text = \" \".join(tokenized_text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXgLeiOLwQaF"
      },
      "outputs": [],
      "source": [
        "ling_df_for[\"setup_out\"]= [clean_first_couple_n_v(s) for s in ling_df_for[\"setup\"]]\n",
        "ling_df_for[\"punchline_out\"] = [clean_first_couple_n_v(s) for s in ling_df_for[\"punchline\"]]\n",
        "ling_df_for[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_for[\"setup_out\"], ling_df_for[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gExSl6yOwQaH"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyCvz1ESwQaK"
      },
      "outputs": [],
      "source": [
        "res_df_nsubjv =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_nsubjv = res_df_nsubjv.rename(columns={\"model_proba\": \"worst_proba\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wEGf8-DwQaL"
      },
      "outputs": [],
      "source": [
        "res_df_nsubjv = res_df_nsubjv.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rx6ZLhLwQaM"
      },
      "outputs": [],
      "source": [
        "res_df_nsubjv.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_only_nsubj.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2ZAsKONxk1R"
      },
      "source": [
        "###### Eliminating a single phrase with elements linked by syntactic relations expl (pleonase nominations), nmod (attribute or complement in the genitive case), or appos (dependent common noun for modifying the first noun)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJx_7_kxxk1T"
      },
      "outputs": [],
      "source": [
        "ling_df_for= ling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz_M28Vuxk1V"
      },
      "outputs": [],
      "source": [
        "def clean_first_couple_n_v(text):\n",
        "  #for item in tqdm(jokes_df.to_dict(orient='records'), total = len(jokes_df.to_dict(orient='records'))):\n",
        "  #tokenized_text = word_tokenize(text)\n",
        "  #tokenized_setup = word_tokenize(item[\"setup\"])\n",
        "  #tokenized_punchline = word_tokenize(item[\"punchline\"])\n",
        "  doc = spacy_model(text)\n",
        "  tokenized_text = [token.text for token in doc]\n",
        "  clean_text = []\n",
        "  for i, token in enumerate(doc):\n",
        "    try:\n",
        "    #w_tag = nltk.pos_tag([w], tagset='universal')[0][1]\n",
        "      if token.dep_ == 'nmod' or token.dep_ == 'expl' or token.dep_ == 'appos' and token.head.text in tokenized_text:\n",
        "        del tokenized_text[i]\n",
        "        tokenized_text.remove(token.head.text)\n",
        "        break\n",
        "      elif token.dep_ != 'nmod' or token.dep_ != 'expl' or token.dep_ != 'appos':\n",
        "        continue\n",
        "    except ValueError as ver:\n",
        "      continue\n",
        "  clean_text = \" \".join(tokenized_text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4YUDILYxk1X"
      },
      "outputs": [],
      "source": [
        "ling_df_for[\"setup_out\"]= [clean_first_couple_n_v(s) for s in ling_df_for[\"setup\"]]\n",
        "ling_df_for[\"punchline_out\"] = [clean_first_couple_n_v(s) for s in ling_df_for[\"punchline\"]]\n",
        "ling_df_for[\"text_out\"] = [\"{} {}\".format(s,p) for s, p in zip(ling_df_for[\"setup_out\"], ling_df_for[\"punchline_out\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrKo0ponxk1Z"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_setup_punch(setup=\"setup_out\", punchline=\"punchline\")),\n",
        "                    pd.DataFrame(get_model_proba_setup_punch(setup=\"setup\", punchline=\"punchline_out\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"text_out\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny8U7UtTxk1c"
      },
      "outputs": [],
      "source": [
        "res_df_thdep =res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_thdep = res_df_thdep.rename(columns={\"model_proba\": \"worst_proba\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRQBQnrRxk1d"
      },
      "outputs": [],
      "source": [
        "res_df_thdep = res_df_thdep.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaarFD22xk1e"
      },
      "outputs": [],
      "source": [
        "res_df_thdep.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_three_deps.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oe1hTp842nn"
      },
      "source": [
        "###### Eliminating individual joke parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuu_7qiw5A_5"
      },
      "outputs": [],
      "source": [
        "res_df = pd.concat([pd.DataFrame(get_model_proba_text(text=\"setup\")),\n",
        "                    pd.DataFrame(get_model_proba_text(text=\"punchline\"))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTx_xZBe5_X2"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out= res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_sp_out = res_df_sp_out.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJeZFMXq6X5C"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out = res_df_sp_out.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMtg0qMo912C"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_setup_punchline_1000.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeDi9Xr8cWBo"
      },
      "source": [
        "###### Eliminating individual joke parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJGWYwhwcWBq"
      },
      "outputs": [],
      "source": [
        "res_df = pd.DataFrame(get_model_proba_text(text=\"setup\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94LKI6ELcWBs"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out= res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_sp_out = res_df_sp_out.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzyDGnVGcWBu"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out = res_df_sp_out.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRA92KdtcWBu"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_setup.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwYkAmzJfFfg"
      },
      "outputs": [],
      "source": [
        "res_df = pd.DataFrame(get_model_proba_text(text=\"punchline\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY-rBQfdfFfi"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out= res_df.merge(res_df.sort_values(by=[\"model_proba\"], ascending=True).groupby([\"id\", \"text\"]).agg({\"model_proba\":\"min\", \"model_res\": \"first\"}).reset_index().reindex(), on= [\"id\", \"text\", \"model_proba\", \"model_res\"], how=\"inner\")\n",
        "\n",
        "res_df_sp_out = res_df_sp_out.rename(columns={\"model_proba\": \"worst_proba\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yocRlWLfFfj"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out = res_df_sp_out.sort_values(by=[\"label_res\", 'id'], ascending=False).reset_index(drop=True).reindex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAM5YC7ZfFfk"
      },
      "outputs": [],
      "source": [
        "res_df_sp_out.to_csv(\"/content/gdrive/MyDrive/trained_models/exp_humor_triggers_delete_punchline.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7BaSxDaNY0x0",
        "ltgh0TxBGYMb",
        "cFSM-qN5FoT6",
        "W3yoJfAQjAqB",
        "rfEtIT6BbxFB",
        "EuBRemnkpS5O",
        "EMCq_bSEgxas",
        "D6WpelMxcy_I",
        "-sGGNO9-agT3",
        "p0gWBnQAYy8e",
        "lw5Qeqn_gx_9",
        "ggC5AXeXNlOo",
        "SKmXVB5_OHkK",
        "p_-xPQoY8NH7",
        "9fmm1KP88hUA",
        "kVXnrpbFqxHc",
        "2OrLnxI5ge16",
        "PWjy3i887_1J",
        "ZHPOz7JrsRwL",
        "3d7ZS9PqDX6c",
        "n5R6bqczImGe",
        "iqGIgeX-ccfY",
        "vwkLFOaTwQZ-",
        "-2ZAsKONxk1R",
        "4oe1hTp842nn",
        "zeDi9Xr8cWBo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}